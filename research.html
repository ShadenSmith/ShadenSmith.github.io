<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Research</title>
  <meta name="description" content="PhD candidate at U. Minnesota. I do research on high performance computing and focus on problems that arise in large scale machine learning.">

  


  <link rel="stylesheet" href="./css/main.css">
  <link rel="canonical" href="./research.html">
  <link rel="alternate" type="application/rss+xml" title="Shaden Smith" href="./feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper navigation-wrapper ">

    <div class="navigation-links">
      


      
      <a class="site-title" href="./">Shaden Smith</a>

      <nav class="site-nav">
        <a href="#" class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
            <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
            <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
          </svg>
        </a>

        <div class="trigger">
          <a class="page-link " href="./index.html" >Home</a>
          
          
            
          
            
          
            
          
            
          
            
            <a class="page-link active" href="./research.html" >Research</a>
            
          
            
            <a class="page-link " href="./personal.html" >Personal</a>
            
          
            
            <a class="page-link " href="./splatt.html" >SPLATT</a>
            
          
            
            <a class="page-link " href="./cv.html" >CV</a>
            
          
            
            <a class="page-link " href="./scholar.html" >Google-Scholar</a>
            
          
        </div>
      </nav>
    </div>
    
    

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Research</h1>
  </header>

  <div class="post-content">
    <p>My research is primarily concerned with the development of scalable, high
performance algorithms for applications in data mining and machine learning.
<em>Irregular</em> applications are of particular interest to me, such as those
that operate on sparse graphs, matrices, and tensors.</p>

<p>My thesis work is focused on large-scale sparse tensor factorization and is
culminated in <a href="https://github.com/ShadenSmith/splatt">SPLATT</a>, an open source
software toolkit for tensor factorization and related kernels. SPLATT has been
scaled to over 16,000 cores and is actively used by academic, industry, and
government researchers.</p>

<h2 id="awards--honors">Awards &amp; Honors</h2>
<ul>
  <li><a href="http://www.acm.org/media-center/2017/august/gm-fellowship-recipients-2017">ACM/IEEE-CS George Michael Memorial HPC Fellowship</a>, 2017</li>
  <li><a href="http://europar2017.usc.es/#conference-program">Euro-Par ‘17 Distinguished Paper</a>,
  “<em>Accelerating the Tucker Decomposition with Compressed Sparse Tensors</em>”.</li>
  <li><a href="http://graphchallenge.mit.edu/champions">HPEC ‘17 GraphChallenge Finalist</a>,
  “<em>Truss Decompositions on Shared-Memory Parallel Systems</em>”</li>
  <li><a href="http://graphchallenge.mit.edu/champions">HPEC ‘17 GraphChallenge Finalist</a>,
  “<em>Exploring Optimizations on Shared-memory Platforms for Parallel Triangle Counting Algorithms</em>”</li>
  <li><a href="">SC ‘16 Best Student Paper Finalist</a>
  “<em>An Exploration of Optimization Algorithms for High Performance Tensor Completion</em>”</li>
  <li><a href="https://www.cs.umn.edu/news/five-named-2016-17-doctoral-dissertation-fellows">Doctoral Dissertation Fellowship</a>, University of Minnesota, 2016-2017</li>
  <li><a href="http://cs.uky.edu/node/356">Outstanding Graduating Senior Award</a>, University of Kentucky, 2012</li>
  <li>Student Internship Symposium Top Prize, Lexmark International, 2011</li>
</ul>

<h2 id="software-contributions">Software Contributions</h2>
<ul>
  <li><a href="http://github.com/ShadenSmith/splatt">SPLATT</a></li>
  <li><a href="http://frostt.io/">FROSTT</a></li>
  <li><a href="https://codesign.llnl.gov/lulesh.php">LULESH</a> (OpenACC port)</li>
  <li><a href="https://github.com/DependableSystemsLab/LLFI">LLFI</a></li>
</ul>

<h2 id="publications">Publications</h2>

<h3 id="book-chapters">Book Chapters</h3>
<ol class="bibliography"><li><span id="anastasiu2014big">[1]David C. Anastasiu, Jeremy Iverson, <b>Shaden Smith</b>, and George Karypis. 2014. Big Data Frequent Pattern Mining. In <i>Frequent Pattern Mining</i>. Springer International Publishing, Switzerland, 225–260.</span>
<br />


  [<a href="/pub-files/anastasiu2014big.pdf">paper</a>]



  [<a href="/pub-files/anastasiu2014big.txt">bib</a>]


</li></ol>

<h3 id="journals">Journals</h3>
<ol class="bibliography"><li><span id="smith2017hpc">[1]<b>Shaden Smith</b> Jongsoo and George Karypis. 2017. HPC formulations of optimization algorithms for tensor completion. <i>Parallel Computing</i> (2017).</span>
<br />


  [<a href="/pub-files/smith2017hpc.pdf">paper</a>]



  [<a href="/pub-files/smith2017hpc.txt">bib</a>]


</li>
<li><span id="anastasiu2016big">[2]David C. Anastasiu, Evangelia Christakopoulou, <b>Shaden Smith</b>, Mohit Sharma, and George Karypis. 2016. Big Data and Recommender Systems. <i>Novática: Journal of the Spanish Computer Scientist Association</i> 240 (October 2016).</span>
<br />


  [<a href="/pub-files/anastasiu2016big.pdf">paper</a>]



  [<a href="/pub-files/anastasiu2016big.txt">bib</a>]


</li></ol>

<h3 id="conferences--refereed-workshops">Conferences &amp; Refereed Workshops</h3>
<ol class="bibliography"><li><span id="choi2018blocking">[1]Jee W. Choi, Xing Liu, <b>Shaden Smith</b>, and Tyler Simon. 2018. Blocking Optimization Techniques for Sparse Tensor Computation. <i>32nd IEEE International Parallel &amp; Distributed Processing Symposium (IPDPS’18)</i> (2018).</span>
<br />





</li>
<li><span id="smith2018streaming">[2]<b>Shaden Smith</b>, Kejun Huang, Nicholas D Sidiropoulos, and George Karypis. 2018. Streaming Tensor Factorization for Infinite Data Sources. <i>Proceedings of the 2018 SIAM International Conference on Data Mining (SDM’18)</i> (2018).</span>
<br />


  [<a href="/pub-files/smith2018streaming.pdf">paper</a>]


  [<a href="/pub-files/smith2018streaming.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2018streaming.txt">bib</a>]


</li>
<li><span id="smith2017truss">[3]<b>Shaden Smith</b>, Xing Liu, Nesreen K. Ahmed, Ancy Sarah Tom, Fabrizio Petrini, and George Karypis. 2017. Truss Decompositions on Shared-Memory Parallel Systems. In <i>IEEE High Performance Extreme Computing Conference (HPEC), <b>GraphChallenge Finalist</b>.</i></span>
<br />


  [<a href="/pub-files/smith2017truss.pdf">paper</a>]


  [<a href="/pub-files/smith2017truss.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2017truss.txt">bib</a>]


</li>
<li><span id="tom2017exploring">[4]Ancy Sarah Tom, Narayanan Sundaram, Nesreen K. Ahmed, <b>Shaden Smith</b>, Stijn Eyerman, Midhunchandra Kodiyath, Ibrahim Hur, Fabrizio Petrini, and George Karypis. 2017. Exploring Optimizations on Shared-memory Platforms for Parallel Triangle Counting Algorithms. In <i>IEEE High Performance Extreme Computing Conference (HPEC), <b>GraphChallenge Finalist</b>.</i></span>
<br />


  [<a href="/pub-files/tom2017exploring.pdf">paper</a>]



  [<a href="/pub-files/tom2017exploring.txt">bib</a>]


</li>
<li><span id="smith2017tucker">[5]<b>Shaden Smith</b> and George Karypis. 2017. Accelerating the Tucker Decomposition with Compressed Sparse Tensors. In <i>European Conference on Parallel Processing (Euro-Par ’17) <b>Distinguished Paper Award</b></i>.</span>
<br />


  [<a href="/pub-files/smith2017tucker.pdf">paper</a>]


  [<a href="/pub-files/smith2017tucker.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2017tucker.txt">bib</a>]


</li>
<li><span id="anderson2017bridging">[6]Michael Anderson, <b>Shaden Smith</b>, Narayanan Sundaram, Mihai Capotă, Zheguang Zhao, Subramanya Dulloor, Nadathur Satish, and Theodore L. Willke. 2017. Bridging the Gap Between HPC and Big Data Frameworks. <i>Proceedings of the VLDB Endowment (PVLDB ’17)</i> (2017).</span>
<br />


  [<a href="/pub-files/anderson2017bridging.pdf">paper</a>]



  [<a href="/pub-files/anderson2017bridging.txt">bib</a>]


</li>
<li><span id="smith2017constrained">[7]<b>Shaden Smith</b>, Alec Beri, and George Karypis. 2017. Constrained Tensor Factorization with Accelerated AO-ADMM. In <i>46th International Conference on Parallel Processing (ICPP ’17)</i>.</span>
<br />


  [<a href="/pub-files/smith2017constrained.pdf">paper</a>]


  [<a href="/pub-files/smith2017constrained.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2017constrained.txt">bib</a>]


</li>
<li><span id="smith2017knl">[8]<b>Shaden Smith</b>, Jongsoo Park, and George Karypis. 2017. Sparse Tensor Factorization on Many-Core Processors with High-Bandwidth Memory. In <i>31st IEEE International Parallel &amp; Distributed Processing Symposium (IPDPS’17)</i>.</span>
<br />


  [<a href="/pub-files/smith2017knl.pdf">paper</a>]


  [<a href="/pub-files/smith2017knl.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2017knl.txt">bib</a>]


</li>
<li><span id="smith2016exploration">[9]<b>Shaden Smith</b>, Jongsoo Park, and George Karypis. 2016. An Exploration of Optimization Algorithms for High Performance Tensor Completion. <i>Proceedings of the 2016 ACM/IEEE Conference on Supercomputing (SC’16) <b>Finalist, Best Student Paper</b></i> (2016).</span>
<br />


  [<a href="/pub-files/smith2016exploration.pdf">paper</a>]


  [<a href="/pub-files/smith2016exploration.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2016exploration.txt">bib</a>]


</li>
<li><span id="smith2016medium">[10]<b>Shaden Smith</b> and George Karypis. 2016. A Medium-Grained Algorithm for Distributed Sparse Tensor Factorization. In <i>30th IEEE International Parallel &amp; Distributed Processing Symposium (IPDPS’16)</i>.</span>
<br />


  [<a href="/pub-files/smith2016medium.pdf">paper</a>]


  [<a href="/pub-files/smith2016medium.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2016medium.txt">bib</a>]


</li>
<li><span id="smith2015splatt">[11]<b>Shaden Smith</b>, Niranjay Ravindran, Nicholas D Sidiropoulos, and George Karypis. 2015. SPLATT: Efficient and parallel sparse tensor-matrix multiplication. In <i>29th IEEE International Parallel &amp; Distributed Processing Symposium (IPDPS’15)</i>.</span>
<br />


  [<a href="/pub-files/smith2015splatt.pdf">paper</a>]


  [<a href="/pub-files/smith2015splatt.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2015splatt.txt">bib</a>]


</li>
<li><span id="smith2015csf">[12]<b>Shaden Smith</b> and George Karypis. 2015. Tensor-Matrix Products with a Compressed Sparse Tensor. <i>Proceedings of the 5th Workshop on Irregular Applications: Architectures and Algorithms (IA3’15)</i> (2015), 7.</span>
<br />


  [<a href="/pub-files/smith2015csf.pdf">paper</a>]


  [<a href="/pub-files/smith2015csf.slides.pdf">slides</a>]


  [<a href="/pub-files/smith2015csf.txt">bib</a>]


</li>
<li><span id="ravindran2014memory">[13]Niranjay Ravindran, Nicholas D Sidiropoulos, <b>Shaden Smith</b>, and George Karypis. 2014. Memory-efficient parallel computation of tensor and matrix products for big tensor decomposition. <i>Proceedings of the Asilomar Conference on Signals, Systems, and Computers</i> (2014).</span>
<br />


  [<a href="/pub-files/ravindran2014memory.pdf">paper</a>]


  [<a href="/pub-files/ravindran2014memory.slides.pdf">slides</a>]


  [<a href="/pub-files/ravindran2014memory.txt">bib</a>]


</li>
<li><span id="lierler2012weighted">[14]Yuliya Lierler, <b>Shaden Smith</b>, Miroslaw Truszczynski, and Alex Westlund. 2012. Weighted-sequence problem: ASP vs CASP and declarative vs problem-oriented solving. <i>Practical Aspects of Declarative Languages (PADL’12)</i> (2012), 63–77.</span>
<br />


  [<a href="/pub-files/lierler2012weighted.pdf">paper</a>]


  [<a href="/pub-files/lierler2012weighted.slides.pdf">slides</a>]


  [<a href="/pub-files/lierler2012weighted.txt">bib</a>]


</li></ol>

<h3 id="invited-talks--posters">Invited Talks &amp; Posters</h3>
<ol class="bibliography"><li><span id="pp18talktucker">[1]<b>Shaden Smith</b> and George Karypis. 2018. Accelerating the Tucker Decomposition with Compressed Sparse Tensors. <i>SIAM Conference on Parallel Processing for Scientific Computing (PP’18),
      Minisymposium: Tensor Decomposition for High Performance Data Analytics</i> (2018).</span>
<br />





</li>
<li><span id="pp18talkgraph">[2]Ancy Sarah Tom, <b>Shaden Smith</b>, and George Karypis. 2018. Triangle Counting and Truss Decomposition on Modern Parallel Architectures. <i>SIAM Conference on Parallel Processing for Scientific Computing (PP’18),
      Minisymposium: Architecture-Aware Graph Analytics</i> (2018).</span>
<br />





</li>
<li><span id="cse17talk">[3]<b>Shaden Smith</b>, Jongsoo Park, and George Karypis. 2017. An Exploration of Optimization Algorithms for High Performance Tensor Completion. <i>SIAM Conference on Computational Science and Engineering
     (CSE’17),
     Minisymposium: Tensor Decompositions: Applications and Efficient Algorithms</i> (2017).</span>
<br />





</li>
<li><span id="intel16talk">[4]<b>Shaden Smith</b> and George Karypis. 2016. High Performance Sparse Tensor Factorization. <i>Intel Research, invited talk</i> (2016).</span>
<br />



  [<a href="/pub-files/intel16talk.slides.pdf">slides</a>]



</li>
<li><span id="pmaa16talk">[5]<b>Shaden Smith</b>, Jongsoo Park, and George Karypis. 2016. An Exploration of Optimization Algorithms for High Performance Tensor Completion. <i>The 9th International Workshop on Parallel Matrix Algorithms and Applications (PMAA’16),
      Minisymposium: Sparse Matrix and Tensor Computations</i> (2016).</span>
<br />



  [<a href="/pub-files/pmaa16talk.slides.pdf">slides</a>]



</li>
<li><span id="pp16talk">[6]<b>Shaden Smith</b> and George Karypis. 2016. Efficient Factorization with Compressed Sparse Tensors. <i>SIAM Conference on Parallel Processing for Scientific Computing (PP’16),
      Minisymposium: Parallel Algorithms for Tensor Computations</i> (2016).</span>
<br />



  [<a href="/pub-files/pp16talk.slides.pdf">slides</a>]



</li>
<li><span id="mmds16poster">[7]<b><b>Shaden Smith</b></b> and George Karypis. 2016. SPLATT: Enabling Large-Scale Sparse Tensor Analysis. </span>
<br />


  [<a href="/pub-files/mmds16poster.pdf">paper</a>]




</li>
<li><span id="luleshtalk">[8]<b>Shaden Smith</b> and Peter Robinson. 2013. LULESH and OpenACC: To Exascale and Beyond!!! <i>PGI OpenACC Workshop</i> (2013).</span>
<br />



  [<a href="/pub-files/luleshtalk.slides.pdf">slides</a>]



</li>
<li><span id="pfmgputalk">[9]<b>Shaden Smith</b> and Jerry Fish. 2012. 2010: A GPU Odyssey. <i>Lexmark Celebrate Success Seminar</i> (2012).</span>
<br />





</li>
<li><span id="pfminterntalk">[10]<b>Shaden Smith</b> and Jerry Fish. 2011. Particle Flow Modeling or: How I Learned to Stop Worrying and
  Love DEM. <i>Lexmark Student Symposium</i> (2011).</span>
<br />





</li></ol>


  </div>

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <ul class="contact-list">
          <li>
            
              Shaden Smith
            
          </li>
          
            
            <a href="http://cs.umn.edu/">
            
            <li>University of Minnesota</li>
            
            </a>
            
          
          <li><a href="mailto:shaden@cs.umn.edu">shaden@cs.umn.edu</a></li>
        </ul>
      </div>

      <div class="footer-col">
      </div>
    </div>
  </div>
  
  

</footer>


  </body>

</html>
